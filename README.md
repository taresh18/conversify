# Conversify âœ¨

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)

Conversify is a realâ€‘time, lowâ€‘latency, voice- and vision-enabled AI assistant built on LiveKit. This project demonstrates highly responsive conversational AI workflows, leveraging locally hosted models.

---

## Table of Contents

1. [Key Features](#key-features)
2. [Prerequisites](#prerequisites)
3. [Installation](#installation)
4. [Running the Application](#running-the-application)
5. [Configuration](#configuration)
6. [Project Structure](#project-structure)
7. [TODO](#todo)
8. [References](#references)
9. [License](#license)

---

## Key Features

- âš¡ **Low Latency**: End-to-end response time under 600â€¯ms.
- ğŸ—£ï¸ **Realâ€‘time Voice**: Natural conversation using local STT and TTS services.
- ğŸ§  **Local LLM Integration**: Compatible with any OpenAIâ€‘style API (e.g., SGLang, vLLM, Ollama).
- ğŸ‘€ **Basic Vision**: Processes video frames with multimodal LLM prompts.
- ğŸ’¾ **Conversational Memory**: Persists context across user sessions.
- ğŸ”§ **Configurable**: All settings managed via `config/config.yaml`.

---

## Prerequisites

- **OS**: Linux or WSL on Windows (tested)
- **Python**: 3.11+
- **Services**:
  - LiveKit Server Cloud (sign up at https://cloud.livekit.io)
  - An LLM inference server with OpenAI-compatible API (e.g., SGLang, vLLM, Ollama)
  - Kokoro FastAPI TTS server (https://github.com/remsky/Kokoro-FastAPI)

---

## Installation

1. **Clone the repository**

    ```bash
    git clone https://github.com/taresh18/conversify-speech.git
    cd conversify-speech
    ```

2. **Create a virtual environment** (recommended)

    ```bash
    python -m venv venv
    source venv/bin/activate    # Linux/macOS
    # venv\Scripts\activate   # Windows
    ```

3. **Install dependencies**

    ```bash
    pip install -r requirements.txt
    ```

4. **Configure environment variables**

    ```bash
    cp .env.example .env.local
    nano .env.local  # Add your LiveKit and other credentials
    ```

5. **Update `config/config.yaml`**

    - Set LLM API endpoint and model names
    - Configure STT/TTS server URLs and parameters
    - Adjust vision and memory settings as needed

---

## Running the Application

Ensure all external services are running before starting Conversify.

1. **Start the LLM server** (example using provided script)

    ```bash
    chmod +x ./scripts/run_llm.sh
    ./scripts/run_llm.sh &
    ```

2. **Start the Kokoro TTS server**

    ```bash
    chmod +x ./scripts/run_kokoro.sh
    ./scripts/run_kokoro.sh &
    ```

3. **Launch Conversify**

    ```bash
    chmod +x ./scripts/run_app.sh
    ./scripts/run_app.sh
    ```

4. **Interact via LiveKit Agents Playground**

    - Navigate to https://agents-playground.livekit.io
    - Select your LiveKit project and room
    - Join and begin conversation

---

## Configuration

All runtime settings are in `config/config.yaml`. Key options include:

- **STT**: model selection and parameters
- **LLM**: endpoint URLs and model names
- **TTS**: voice options and server settings
- **Vision**: enable/disable frame analysis and thresholds
- **Memory**: persistence and retrieval parameters
- **Logging**: level and file path (`app.log`)

Secrets and credentials reside in `.env.local`, following the template in `.env.example`.

---

## Project Structure

```plaintext
conversify-speech/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml         # All application settings
â”œâ”€â”€ conversify/
â”‚   â”œâ”€â”€ core/               # Orchestration and agent logic
â”‚   â”œâ”€â”€ stt/                # Speech-to-text client
â”‚   â”œâ”€â”€ tts/                # Text-to-speech client
â”‚   â”œâ”€â”€ llm/                # LLM integration client
â”‚   â”œâ”€â”€ livekit/            # LiveKit session & media management
â”‚   â””â”€â”€ utils/              # Logger and shared utilities
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ llm.txt             # System prompt for LLM
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_llm.sh
â”‚   â”œâ”€â”€ run_kokoro.sh
â”‚   â””â”€â”€ run_app.sh
â”œâ”€â”€ .env.example            # Template for environment variables
â”œâ”€â”€ .env.local              # Local secrets (ignored)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## TODO / Future Ideas

- Enhance vision-triggered actions and robustness
- Optimize memory retrieval strategies
- Support alternative TTS engines (e.g., Orpheus, Sesame-CSM)
- Add tool-calling capabilities for structured LLM plugins
- Include CI/CD and automated testing workflows

---

## References

- LiveKit Agents: https://github.com/livekit/agents
- Faster Whisper: https://github.com/SYSTRAN/faster-whisper
- Kokoro FastAPI: https://github.com/remsky/Kokoro-FastAPI
- Memoripy: https://github.com/caspianmoon/memoripy

---

## License

This project is released under the Apache License 2.0. See the [LICENSE](LICENSE) file for details.

